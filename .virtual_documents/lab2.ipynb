








import numpy as np
import time
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, accuracy_score





X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)





X = X.astype('float32') / 255.0
y = y.astype(int)





X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)





mlp = MLPClassifier(
    hidden_layer_sizes=(128, 64),
    max_iter=20,
    activation='relu',
    solver='adam',
    batch_size=256,
    random_state=42
)

start_time_mlp = time.time()
mlp.fit(X_train, y_train)
end_time_mlp = time.time()
print(f"Time: {end_time_mlp - start_time_mlp} sec.")


y_pred = mlp.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, digits=4))








import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader





X_train_torch = torch.tensor(X_train).reshape(-1, 1, 28, 28)
X_test_torch = torch.tensor(X_test).reshape(-1, 1, 28, 28)
y_train_torch = torch.tensor(y_train, dtype=torch.long)
y_test_torch = torch.tensor(y_test, dtype=torch.long)

train_dataset = TensorDataset(X_train_torch, y_train_torch)
test_dataset = TensorDataset(X_test_torch, y_test_torch)

BATCH_SIZE = 64
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")





class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        # 1-й сверточный слой (1 канал -> 6 выходных каналов)
        # Вход: 1x28x28. После Conv(5x5, stride=1): 6x24x24
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)
        # После MaxPool(2x2, stride=2): 6x12x12
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        # 2-й сверточный слой (6 каналов -> 16 выходных каналов)
        # Вход: 6x12x12. После Conv(5x5, stride=1): 16x8x8
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
        # После MaxPool(2x2, stride=2): 16x4x4
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Полносвязные слои
        # Входной размер: 16 каналов * 4 * 4 = 256
        self.fc1 = nn.Linear(16 * 4 * 4, 120)
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(120, 84)
        self.relu4 = nn.ReLU()
        self.fc3 = nn.Linear(84, 10) # 10 классов (цифры от 0 до 9)

    def forward(self, x):
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        # Выравнивание тензора (flatten) для полносвязных слоев
        x = x.view(-1, 16 * 4 * 4)
        x = self.relu3(self.fc1(x))
        x = self.relu4(self.fc2(x))
        x = self.fc3(x)
        return x


model = LeNet().to(device)





def train_cnn(model, loader, criterion, optimizer, device, num_epochs):
    model.train()
    start_time = time.time()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad() # Обнуляем градиенты

            outputs = model(inputs) # Прямой проход
            loss = criterion(outputs, labels) # Вычисление ошибки
            loss.backward() # Обратный проход
            optimizer.step() # Обновление весов

            running_loss += loss.item() * inputs.size(0)
        
        epoch_loss = running_loss / len(loader.dataset)
        print("Epoch", epoch+1, "/", num_epochs, "Loss:", epoch_loss)
    
    end_time = time.time()
    return end_time - start_time


CRITERION = nn.CrossEntropyLoss()
OPTIMIZER = optim.Adam(model.parameters(), lr=0.001)
NUM_EPOCHS = 20
training_time_cnn = train_cnn(model, train_loader, CRITERION, OPTIMIZER, device, NUM_EPOCHS)


def evaluate_cnn(model, loader, device):
    model.eval()
    y_true = []
    y_pred = []
    correct = 0
    total = 0
    with torch.no_grad(): # Отключение вычисления градиентов для экономии памяти
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            
            _, predicted = torch.max(outputs.data, 1)
            
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

    accuracy = correct / total
    return accuracy, y_true, y_pred

# Оценка
accuracy_cnn, y_test_true_cnn, y_pred_cnn = evaluate_cnn(model, test_loader, device)

print(f"Time: {training_time_cnn:.2f} sec.")
print(f"Accuracy: {accuracy_cnn}")
print(classification_report(y_test_true_cnn, y_pred_cnn, digits=4))






