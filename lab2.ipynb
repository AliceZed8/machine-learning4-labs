{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22481e3f-8d85-4bb4-83ff-ee01f8a5603c",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d73c6b-408f-4f17-bfe7-b3c804dddda7",
   "metadata": {},
   "source": [
    "Решить задачу классификации датасета MNIST используя MLP из scikitlearn и используя CNN (по типу LeNet) c пакетом PyTorch. \\\n",
    "Сравнить результаты по метрикам, сделать обоснованные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ad6cb-5cd9-45df-96ad-d876803a4c12",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36011a5b-7332-4250-af99-5290d09f1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e594ee2-d579-4b81-9a8d-4654925d4421",
   "metadata": {},
   "source": [
    "Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1401d43e-8340-4834-adf1-ae360ec6665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef4914-311e-4691-9c65-05ca39af153e",
   "metadata": {},
   "source": [
    "Нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7819d38d-3db3-42c1-ad8e-06837ecb29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32') / 255.0\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07325678-bd4a-46c3-b6de-b6cdca353651",
   "metadata": {},
   "source": [
    "Разделение на обучающий и тестовый набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f643bbdc-08e7-41d9-8157-356e79b45085",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6539bd-81dd-4147-b435-2f6ff4de36fb",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7961121b-7f60-4c62-94eb-3c5f72f416bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 17.673134803771973 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alice/.pyenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    max_iter=20,\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    batch_size=256,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "start_time_mlp = time.time()\n",
    "mlp.fit(X_train, y_train)\n",
    "end_time_mlp = time.time()\n",
    "print(f\"Time: {end_time_mlp - start_time_mlp} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6545e916-4825-4445-a5d8-ebf7bcbc425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9755238095238096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9873    0.9830    0.9851      2058\n",
      "           1     0.9857    0.9898    0.9878      2364\n",
      "           2     0.9694    0.9808    0.9751      2133\n",
      "           3     0.9731    0.9632    0.9681      2176\n",
      "           4     0.9733    0.9788    0.9760      1936\n",
      "           5     0.9693    0.9723    0.9708      1915\n",
      "           6     0.9732    0.9923    0.9827      2088\n",
      "           7     0.9811    0.9715    0.9763      2248\n",
      "           8     0.9693    0.9659    0.9676      1992\n",
      "           9     0.9713    0.9560    0.9636      2090\n",
      "\n",
      "    accuracy                         0.9755     21000\n",
      "   macro avg     0.9753    0.9754    0.9753     21000\n",
      "weighted avg     0.9755    0.9755    0.9755     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e30ab-03bc-4dde-9047-11ae91d25bfd",
   "metadata": {},
   "source": [
    "Особенности MLP:\n",
    "- Простая реализация\n",
    "- Быстро обучается\n",
    "- Игнорирует геометрию изображения\n",
    "- Хуже различает похожие цифры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfc3f2-a161-42c3-994e-99d6216294e5",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2687f9e1-e0e3-4764-ac30-1737c3975782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a600b7-7ed9-48de-b636-02a4985d0ed6",
   "metadata": {},
   "source": [
    "Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48237bf-fd0d-45ea-a0ff-f567cb89dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.tensor(X_train).reshape(-1, 1, 28, 28)\n",
    "X_test_torch = torch.tensor(X_test).reshape(-1, 1, 28, 28)\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_torch = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "test_dataset = TensorDataset(X_test_torch, y_test_torch)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0eadfd-e2ef-4d31-bf51-b6ff04a625d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309fdd4-03f6-45bf-ba44-295cac1a1bdb",
   "metadata": {},
   "source": [
    "Сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d9f0c45-e779-4c67-b81c-859fdce60ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1-й сверточный слой (1 канал -> 6 выходных каналов)\n",
    "        # Вход: 1x28x28. После Conv(5x5, stride=1): 6x24x24\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        # После MaxPool(2x2, stride=2): 6x12x12\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 2-й сверточный слой (6 каналов -> 16 выходных каналов)\n",
    "        # Вход: 6x12x12. После Conv(5x5, stride=1): 16x8x8\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        # После MaxPool(2x2, stride=2): 16x4x4\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Полносвязные слои\n",
    "        # Входной размер: 16 каналов * 4 * 4 = 256\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10) # 10 классов (цифры от 0 до 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        # Выравнивание тензора (flatten) для полносвязных слоев\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9040ecf-a577-4c53-ab2c-96501464bb6f",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37043965-bd10-42de-92d5-d56c67890891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(model, loader, criterion, optimizer, device, num_epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # Обнуляем градиенты\n",
    "\n",
    "            outputs = model(inputs) # Прямой проход\n",
    "            loss = criterion(outputs, labels) # Вычисление ошибки\n",
    "            loss.backward() # Обратный проход\n",
    "            optimizer.step() # Обновление весов\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(loader.dataset)\n",
    "        print(\"Epoch\", epoch+1, \"/\", num_epochs, \"Loss:\", epoch_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2332745e-4cd4-4787-a5ca-a8b35faa0f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 20 Loss: 0.32007292953376865\n",
      "Epoch 2 / 20 Loss: 0.08946778539370517\n",
      "Epoch 3 / 20 Loss: 0.06338726250431975\n",
      "Epoch 4 / 20 Loss: 0.050906627253154105\n",
      "Epoch 5 / 20 Loss: 0.04236909556578921\n",
      "Epoch 6 / 20 Loss: 0.0360330908167347\n",
      "Epoch 7 / 20 Loss: 0.0303836109467535\n",
      "Epoch 8 / 20 Loss: 0.026606045364877397\n",
      "Epoch 9 / 20 Loss: 0.02337437690205264\n",
      "Epoch 10 / 20 Loss: 0.020521667275839123\n",
      "Epoch 11 / 20 Loss: 0.017740705186900282\n",
      "Epoch 12 / 20 Loss: 0.017130295392672284\n",
      "Epoch 13 / 20 Loss: 0.014796193687748925\n",
      "Epoch 14 / 20 Loss: 0.012822255553876059\n",
      "Epoch 15 / 20 Loss: 0.011531907941849086\n",
      "Epoch 16 / 20 Loss: 0.011323884834875163\n",
      "Epoch 17 / 20 Loss: 0.010408526655409797\n",
      "Epoch 18 / 20 Loss: 0.011482389807268711\n",
      "Epoch 19 / 20 Loss: 0.008214721758592142\n",
      "Epoch 20 / 20 Loss: 0.005623247039574436\n"
     ]
    }
   ],
   "source": [
    "CRITERION = nn.CrossEntropyLoss()\n",
    "OPTIMIZER = optim.Adam(model.parameters(), lr=0.001)\n",
    "NUM_EPOCHS = 20\n",
    "training_time_cnn = train_cnn(model, train_loader, CRITERION, OPTIMIZER, device, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e76aad-c2ec-4c85-a478-63b94373b472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 68.40 sec.\n",
      "Accuracy: 0.9870476190476191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9923    0.9961    0.9942      2058\n",
      "           1     0.9962    0.9966    0.9964      2364\n",
      "           2     0.9827    0.9869    0.9848      2133\n",
      "           3     0.9875    0.9807    0.9841      2176\n",
      "           4     0.9932    0.9788    0.9860      1936\n",
      "           5     0.9900    0.9781    0.9840      1915\n",
      "           6     0.9848    0.9933    0.9890      2088\n",
      "           7     0.9950    0.9800    0.9874      2248\n",
      "           8     0.9811    0.9880    0.9845      1992\n",
      "           9     0.9673    0.9904    0.9787      2090\n",
      "\n",
      "    accuracy                         0.9870     21000\n",
      "   macro avg     0.9870    0.9869    0.9869     21000\n",
      "weighted avg     0.9871    0.9870    0.9871     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_cnn(model, loader, device):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # Отключение вычисления градиентов для экономии памяти\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy, y_true, y_pred\n",
    "\n",
    "# Оценка\n",
    "accuracy_cnn, y_test_true_cnn, y_pred_cnn = evaluate_cnn(model, test_loader, device)\n",
    "\n",
    "print(f\"Time: {training_time_cnn:.2f} sec.\")\n",
    "print(f\"Accuracy: {accuracy_cnn}\")\n",
    "print(classification_report(y_test_true_cnn, y_pred_cnn, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f873f0-8ac4-4de2-a557-89bd35bb48af",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "CNN (LeNet-подобная) демонстрирует значительно более высокую точность (98-99%) по сравнению с MLP (96-97%). \\\n",
    "Причина: CNN специально разработана для обработки изображений. Сверточные слои (nn.Conv2d) способны автоматически изучать пространственные и иерархические признаки (границы, углы, формы) из исходных пикселей. \\\n",
    "MLP обрабатывает входные данные как плоский вектор (784 признака), теряя информацию о пространственной близости между пикселями. \\\n",
    "Для MLP пиксель в верхнем левом углу так же \"связан\" с пикселем в нижнем правом углу, как и с соседним пикселем, что неверно для изображений.\n",
    "\n",
    "CNN использует общие веса (share weights) в пределах одного сверточного фильтра, что значительно уменьшает количество параметров по сравнению с полностью связанной (полносвязной) сетью с таким же количеством нейронов. Это делает CNN более эффективной и менее склонной к переобучению при работе с изображениями.\n",
    "\n",
    "Сложность реализации и фреймворки:\n",
    "- MLP с scikit-learn — очень простая реализация, идеальна для быстрого прототипирования.\n",
    "- CNN с PyTorch — требует больше кода (определение класса сети, циклы обучения с батчами, оптимизатор, функция потерь), но дает полный контроль над архитектурой и процессом обучения, что необходимо для более сложных задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01657d66-d636-48ef-b409-f82ab378c302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
